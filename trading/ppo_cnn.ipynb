{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch as th\n",
    "from torch.nn import functional as F\n",
    "from trade_tester.env import TradingEnv2Actions\n",
    "import talib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klines = pd.read_csv('klines/DOGEUSDT_15m.csv')[['open_time', 'open', 'close', 'high', 'low', 'vol', 'trades']]\n",
    "klines = klines.rename({'open_time': 'date'}, axis=1)\n",
    "klines['date'] = pd.to_datetime(klines['date'], unit='ms')\n",
    "klines['bb_upper'], klines['bb_middle'], klines['bb_lower'] = talib.BBANDS(klines['close'], 200, 2, 2)\n",
    "klines_train = klines.iloc[len(klines)-50000: len(klines)-10000]\n",
    "klines_validate = klines.iloc[len(klines)-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveBestModelCallback(BaseCallback):\n",
    "    def __init__(self, save_path: str, verbose: int = 0):\n",
    "        super(SaveBestModelCallback, self).__init__(verbose)\n",
    "        self.save_path = save_path\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % 1000 == 0:\n",
    "            mean_reward = np.mean(self.locals[\"rollout_buffer\"].rewards)\n",
    "            if mean_reward > self.best_mean_reward:\n",
    "                self.best_mean_reward = mean_reward\n",
    "                self.model.save(os.path.join(self.save_path, \"best_model\"))\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPolicy(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, features_dim) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        channels = observation_space.shape[1]\n",
    "        kernel_conv = 8\n",
    "        pooling_kernel = 2\n",
    "        conv1_out = 32\n",
    "\n",
    "        len_conv_out = int(conv1_out * ((observation_space.shape[0] - kernel_conv) / 1 + 1))\n",
    "        pooling_out = int((len_conv_out - pooling_kernel) / pooling_kernel + 1)\n",
    "\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=channels, out_channels=8, kernel_size=kernel_conv),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(in_channels=8, out_channels=16, kernel_size=kernel_conv),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv1d(in_channels=16, out_channels=conv1_out, kernel_size=kernel_conv),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.MaxPool1d(kernel_size=pooling_kernel),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(pooling_out - 64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, features_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: th.Tensor) -> th.Tensor:\n",
    "        x = x.transpose(1, 2)\n",
    "        return self.nn(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the env\n",
    "indicators = [\n",
    "    dict(name='bb_upper', color='yellow'),\n",
    "    dict(name='bb_middle', color='yellow'),\n",
    "    dict(name='bb_lower', color='yellow'),\n",
    "]\n",
    "\n",
    "env_kwargs = dict(\n",
    "        klines=klines_train,\n",
    "        window=300,\n",
    "        b_size=1000,\n",
    "        tester='BBFutureTester',\n",
    "        # features=['open', 'high', 'low', 'close'],\n",
    "        tester_kwargs = dict(\n",
    "            depo=1000,\n",
    "            TP=0.5,\n",
    "            SL=0.25,\n",
    "            indicators = indicators,\n",
    "        ),\n",
    "    )\n",
    "num_envs = 1\n",
    "env = DummyVecEnv([lambda: Monitor(TradingEnv2Actions(**env_kwargs)) for i in range(num_envs)])\n",
    "# env = make_vec_env(TradingEnv2Actions, n_envs=4, env_kwargs=env_kwargs)\n",
    "# env = TradingEnv2Actions(**env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the policy network architecture\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomPolicy,\n",
    "    features_extractor_kwargs=dict(features_dim=env.action_space.n),\n",
    "    optimizer_kwargs=dict(optim_cls=th.optim.Adam, optim_kwargs=dict(lr=3e-4)),\n",
    "    normalize_images=False,\n",
    ")\n",
    "save_path = \"./ppo_best\"\n",
    "\n",
    "try:\n",
    "    model = PPO.load(save_path + '/best_model')\n",
    "    model.set_env(env)\n",
    "except:\n",
    "    # Define the model\n",
    "    model = PPO(\n",
    "        policy=\"CnnPolicy\",\n",
    "        env=env,\n",
    "        tensorboard_log='tblog',\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        # learning_rate=0.001,\n",
    "        gamma=0.8,\n",
    "        verbose=1,\n",
    "        batch_size=256,\n",
    "        n_steps=4096,\n",
    "    )\n",
    "callback = SaveBestModelCallback(save_path)\n",
    "model.learn(total_timesteps=int(1e5), callback=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the env\n",
    "indicators = [\n",
    "    dict(name='bb_upper', color='yellow'),\n",
    "    dict(name='bb_middle', color='yellow'),\n",
    "    dict(name='bb_lower', color='yellow'),\n",
    "]\n",
    "\n",
    "env_kwargs = dict(\n",
    "        klines=klines_validate,\n",
    "        window=300,\n",
    "        # b_size=3000,\n",
    "        tester='BBFutureTester',\n",
    "        # features=['open', 'high', 'low', 'close'],\n",
    "        tester_kwargs = dict(\n",
    "            depo=1000,\n",
    "            indicators = indicators,\n",
    "        ),\n",
    "        risk=0.1,\n",
    "    )\n",
    "env = TradingEnv2Actions(**env_kwargs)\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.reshape(9, 300).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Создание случайных данных для временного ряда\n",
    "temperature = torch.randn(168)\n",
    "humidity = torch.randn(168)\n",
    "pressure = torch.randn(168)\n",
    "\n",
    "# Создание временного ряда из трех переменных\n",
    "data = torch.stack([temperature, humidity, pressure], dim=1)\n",
    "data.shape\n",
    "# data[-6:][:, None].reshape(1, 3, 6)\n",
    "plt.plot(temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0, 100, 0.1)\n",
    "data_sin = np.sin(time)\n",
    "data_cos = np.cos(time)\n",
    "data = np.column_stack((data_sin, data_cos))\n",
    "tens = torch.from_numpy(data[-6:].reshape(2, 6)).float()\n",
    "tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16 * ((6 - 3) / 1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_length_conv1d = (sequence_length + 2 * padding - kernel_size) // stride + 1\n",
    "\n",
    "m = nn.Conv1d(2, 16, 3)\n",
    "m(tens).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = nn.MaxPool1d(kernel_size=2)\n",
    "mp(m(tens)).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(1, 10, 1)\n",
    "b = np.arange(100, 1000, 100)\n",
    "c = th.tensor(np.column_stack((a, b))[None, :], dtype=torch.float32)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
